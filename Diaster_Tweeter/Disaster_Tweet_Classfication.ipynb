{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b68391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('C:/Users/USER/Desktop/Data_Practices/Diaster_Tweeter/train.csv')\n",
    "test_df = pd.read_csv('C:/Users/USER/Desktop/Data_Practices/Diaster_Tweeter/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d10425",
   "metadata": {},
   "source": [
    "## 훈련 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e581b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ca7ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키워드에 대한 변수 확인\n",
    "train_df.keyword.unique()[:10]\n",
    "# 키워드에 따라 어떤 정보가 주어져있을 가능성이 매우 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17f1d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target에 대한 정보 확인\n",
    "train_df.target.value_counts()\n",
    "# 재난 트윗 3271건, 비재난 트윗 4342건 발생\n",
    "# 주어진 데이터는 크게 불균형이 발생하지 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666663b4",
   "metadata": {},
   "source": [
    "## 문자열 정제\n",
    "다음과 같은 정제가 필요할 것이다.  \n",
    "1. 영어이므로 대소문자를 통일한다.\n",
    "2. 특수기호 등을 없애줘야 한다.  \n",
    "3. 의미 없는 문법에 의한 단어들(stopwords)를 제거한다.\n",
    "\n",
    "이 중 stop_words의 경우에는, tf-idf vectorizer 과정에서 지정가능하므로\n",
    "나머지 과정에 대해 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd97235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text) # 괄호 제거\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # 링크 제거\n",
    "    text = re.sub('<.*?>+', '', text) \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) #구두점 제거\n",
    "    text = re.sub('\\n', '', text) # \n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdf91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text = train_df.text.apply(lambda s : clean_text(s))\n",
    "test_df.text = test_df.text.apply(lambda s : clean_text(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f75e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ariaahrary thetawniest the out of control wild...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s of volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the latest more homes razed by northern califo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deeds are the reason of this earthquake ma...       1  \n",
       "1                 forest fire near la ronge sask canada       1  \n",
       "2     all residents asked to shelter in place are be...       1  \n",
       "3      people receive wildfires evacuation orders in...       1  \n",
       "4     just got sent this photo from ruby alaska as s...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  two giant cranes holding a bridge collapse int...       1  \n",
       "7609  ariaahrary thetawniest the out of control wild...       1  \n",
       "7610                               s of volcano hawaii        1  \n",
       "7611  police investigating after an ebike collided w...       1  \n",
       "7612  the latest more homes razed by northern califo...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00d0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna('.')\n",
    "test_df = test_df.fillna('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ce05d",
   "metadata": {},
   "source": [
    "## Vectorizer 적용 후의 간단한 분류 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7732a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "train_vec = tfidf.fit_transform(train_df.text)\n",
    "test_vec = tfidf.transform(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25022c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ca6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59398496 0.58263773 0.6460251  0.60493827 0.73635665]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_nb = MultinomialNB()\n",
    "scores = cross_val_score(clf_nb, train_vec, train_df['target'], cv = 5,\n",
    "                        scoring = 'f1')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f786400",
   "metadata": {},
   "source": [
    "## 모델 개선 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee6f78",
   "metadata": {},
   "source": [
    "다음에 대해 고려하고 모델을 적용해보자.  \n",
    "- 단어의 기본형만 사용할 수 없을 것인가?\n",
    "- 다른 벡터화는 존재하지 않는가?\n",
    "- 다른 정보를 사용할 수는 없을 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e606b8",
   "metadata": {},
   "source": [
    "### lemmatizer(표제어 추출)\n",
    "이 과정을 통해 단어를 표제어 기준의 형태로 변경해볼 수 있다.  \n",
    "하지만 이를 위해서는 위의 형태로 진행하는 것이 아닌 토큰화를 별도로 진행해야 할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44c68933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1008ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemmatize_result = \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    \n",
    "    return lemmatize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55de6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text = train_df.text.apply(lambda s : text_preprocess(s))\n",
    "test_df.text = test_df.text.apply(lambda s : text_preprocess(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9cd4fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>our deed are the reason of this earthquake may...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>all resident asked to shelter in place are bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>just got sent this photo from ruby alaska a sm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>two giant crane holding a bridge collapse into...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>ariaahrary thetawniest the out of control wild...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>s of volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>the latest more home razed by northern califor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1       .        .   \n",
       "1         4       .        .   \n",
       "2         5       .        .   \n",
       "3         6       .        .   \n",
       "4         7       .        .   \n",
       "...     ...     ...      ...   \n",
       "7608  10869       .        .   \n",
       "7609  10870       .        .   \n",
       "7610  10871       .        .   \n",
       "7611  10872       .        .   \n",
       "7612  10873       .        .   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deed are the reason of this earthquake may...       1  \n",
       "1                 forest fire near la ronge sask canada       1  \n",
       "2     all resident asked to shelter in place are bei...       1  \n",
       "3     people receive wildfire evacuation order in ca...       1  \n",
       "4     just got sent this photo from ruby alaska a sm...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  two giant crane holding a bridge collapse into...       1  \n",
       "7609  ariaahrary thetawniest the out of control wild...       1  \n",
       "7610                                s of volcano hawaii       1  \n",
       "7611  police investigating after an ebike collided w...       1  \n",
       "7612  the latest more home razed by northern califor...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aad4e35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59128823 0.60855263 0.64585045 0.61672474 0.74294432]\n"
     ]
    }
   ],
   "source": [
    "# 추가 전처리 후 동일 모델로 재평가\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "train_vec = tfidf.fit_transform(train_df.text)\n",
    "test_vec = tfidf.transform(test_df.text)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "scores = cross_val_score(clf_nb, train_vec, train_df['target'], cv = 5,\n",
    "                        scoring = 'f1')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74298551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62966031 0.60770328 0.65671642 0.66010598 0.73203492]\n"
     ]
    }
   ],
   "source": [
    "# 다른 vectorizer 활용\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt = CountVectorizer(stop_words = 'english')\n",
    "train_vec = cnt.fit_transform(train_df.text)\n",
    "test_vec = cnt.transform(test_df.text)\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "scores = cross_val_score(clf_nb, train_vec, train_df['target'], cv = 5,\n",
    "                        scoring = 'f1')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ddf81f",
   "metadata": {},
   "source": [
    "count vectorzier에서 더 좋은 성능을 보이고 있는데, 이는 재난 문자에서는 공통적인 키워드가 들어가 있을 것이기에, 그 공통적인 키워드의 빈출을 살리기 위해서는 문서별 특이어를 잡아주는 TF-IDF보다는 공통어에 치중된 CountVectorzier의 성능이 더 좋을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63342b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
