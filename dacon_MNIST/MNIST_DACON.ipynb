{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea116a7c",
   "metadata": {},
   "source": [
    "## Dacon_손글씨 분류 대회를 통한 딥러닝 기초 부수기(?)(Pytorch맛)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d5f4d",
   "metadata": {},
   "source": [
    "딥러닝의 가장 기본적인 예시를 통해, pytorch를 복습하면서 가장 기본적인 딥러닝을 다시 처음부터 공부해보았습니다.\n",
    "간단한 해설(?)과 함께 어떻게 진행하였는지 결과를 보고자 합니다.\n",
    "baseline을 활용하였으며, 추가 모델은 직접 만들어보았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70913e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b984c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/USER/Desktop/data_Practices/dacon_MNIST/train/train_data.csv')\n",
    "test_df = pd.read_csv('C:/Users/USER/Desktop/data_Practices/dacon_MNIST/test/test_data.csv')\n",
    "submission = pd.read_csv('C:/Users/USER/Desktop/data_Practices/dacon_MNIST/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e3b70",
   "metadata": {},
   "source": [
    "## 데이터 기본 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70d48f",
   "metadata": {},
   "source": [
    "우선 이번 문제에서의 train, test 현황 등을 확인해보고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f796a011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train0001.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train0002.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train0003.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train0004.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train0005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>train4996.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>train4997.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>train4998.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>train4999.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>train5000.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name  label\n",
       "0     train0001.png      8\n",
       "1     train0002.png      8\n",
       "2     train0003.png      8\n",
       "3     train0004.png      8\n",
       "4     train0005.png      8\n",
       "...             ...    ...\n",
       "4995  train4996.png      6\n",
       "4996  train4997.png      6\n",
       "4997  train4998.png      6\n",
       "4998  train4999.png      6\n",
       "4999  train5000.png      6\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc2813",
   "metadata": {},
   "source": [
    "원래 우리가 알던 MNIST와 다르게, 훈련 데이터가 5000개 뿐이다. 이에 대한 전략을 생각해 봐야 할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa5fe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>idx0001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idx0002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>idx0003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>idx0004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idx0005.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>idx4996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>idx4997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>idx4998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>idx4999.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>idx5000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name\n",
       "0     idx0001.png\n",
       "1     idx0002.png\n",
       "2     idx0003.png\n",
       "3     idx0004.png\n",
       "4     idx0005.png\n",
       "...           ...\n",
       "4995  idx4996.png\n",
       "4996  idx4997.png\n",
       "4997  idx4998.png\n",
       "4998  idx4999.png\n",
       "4999  idx5000.png\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c94519",
   "metadata": {},
   "source": [
    "테스트 데이터도 5000개를 맞춰야 합니다.\n",
    "조금 특이한 부분은 일반적인 MNIST 문제는 6만개 정도의 데이터를 학습하는 반면에, 여기서는 5000개를 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466205c",
   "metadata": {},
   "source": [
    "## 첫 번째 관문, 이미지를 불러오는 방법!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d971656a",
   "metadata": {},
   "source": [
    "이미지를 어떻게 불러올지에 대해 baseline을 바탕으로 이해해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fc701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c969d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_dir = 'C:/Users/USER/Desktop/data_Practices/dacon_MNIST/train/'\n",
    "sample_file = train_df['file_name'][0]\n",
    "\n",
    "sample_image_array = np.array(Image.open(file_dir + sample_file))\n",
    "\n",
    "plt.imshow(sample_image_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb594fe7",
   "metadata": {},
   "source": [
    "다음과 같이 픽셀 형태로 잘려서 나옴을 알 수 있다. 이 그림의 크기라던가 기타 정보를 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22eb2f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746625f",
   "metadata": {},
   "source": [
    "해당 그림은 가로 28픽셀, 세로 28픽셀 형태의 그림이구나 라고 생각할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d60dcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>185</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>128</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>241</td>\n",
       "      <td>251</td>\n",
       "      <td>216</td>\n",
       "      <td>252</td>\n",
       "      <td>240</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>254</td>\n",
       "      <td>248</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>49</td>\n",
       "      <td>91</td>\n",
       "      <td>245</td>\n",
       "      <td>244</td>\n",
       "      <td>125</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>254</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>254</td>\n",
       "      <td>169</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>250</td>\n",
       "      <td>211</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>254</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>254</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>245</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>235</td>\n",
       "      <td>231</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>254</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>254</td>\n",
       "      <td>140</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>254</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>244</td>\n",
       "      <td>254</td>\n",
       "      <td>174</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>254</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>177</td>\n",
       "      <td>254</td>\n",
       "      <td>232</td>\n",
       "      <td>167</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>218</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>196</td>\n",
       "      <td>160</td>\n",
       "      <td>199</td>\n",
       "      <td>235</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>254</td>\n",
       "      <td>195</td>\n",
       "      <td>31</td>\n",
       "      <td>188</td>\n",
       "      <td>216</td>\n",
       "      <td>226</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>250</td>\n",
       "      <td>239</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>168</td>\n",
       "      <td>237</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>254</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>238</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>254</td>\n",
       "      <td>227</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>250</td>\n",
       "      <td>245</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>254</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>254</td>\n",
       "      <td>238</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>254</td>\n",
       "      <td>222</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>254</td>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>254</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>188</td>\n",
       "      <td>254</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>254</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>254</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>212</td>\n",
       "      <td>249</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>182</td>\n",
       "      <td>232</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7    8    9    10   11   12   13   14   15  \\\n",
       "0    0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "1    0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "2    0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "3    0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "4    0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "5    0   0   0   0   0   0   0   0    0    0   37  185  254  254  128   42   \n",
       "6    0   0   0   0   0   0   0   0    2  129  241  251  216  252  240  243   \n",
       "7    0   0   0   0   0   0   0   0  122  254  248  122    0  145   49   91   \n",
       "8    0   0   0   0   0   0   0   0  198  254  113    0    0    0    0    0   \n",
       "9    0   0   0   0   0   0   0  36  250  211   15    0    0    0    0    0   \n",
       "10   0   0   0   0   0   0   0  38  254  178    0    0    0    0    0    0   \n",
       "11   0   0   0   0   0   0   0  26  235  231   13    0    0    0    0    0   \n",
       "12   0   0   0   0   0   0   0   0  177  254  140   11    0    0    0    0   \n",
       "13   0   0   0   0   0   0   0   0   23  244  254  174   19    0    0    0   \n",
       "14   0   0   0   0   0   0   0   0    0   72  177  254  232  167   14    0   \n",
       "15   0   0   0   0   0   0   0   0    0    0   48  254  254  254  254  255   \n",
       "16   0   0   0   0   0   0   0   0    0    0  180  254  195   31  188  216   \n",
       "17   0   0   0   0   0   0   0   0    0   59  250  239   17    0    0    0   \n",
       "18   0   0   0   0   0   0   0   0    3  163  254  143    0    0    0    0   \n",
       "19   0   0   0   0   0   0   0   0   10  254  227   21    0    0    0    0   \n",
       "20   0   0   0   0   0   0   0   0   10  254  206    0    0    0    0    0   \n",
       "21   0   0   0   0   0   0   0   0   10  254  222   16    0    0    0    0   \n",
       "22   0   0   0   0   0   0   0   0    1  172  254  124    0    0    0    0   \n",
       "23   0   0   0   0   0   0   0   0    0   90  254  235    0    0    0    0   \n",
       "24   0   0   0   0   0   0   0   0    0   48  212  249   91    0    0    0   \n",
       "25   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "26   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "27   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "     16   17   18   19   20   21   22   23  24  25  26  27  \n",
       "0     0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "1     0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "2     0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "3     0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "4     0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "5     0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "6   167   43    0    0    0    0    0    0   0   0   0   0  \n",
       "7   245  244  125   35    0    0    0    0   0   0   0   0  \n",
       "8     0  170  254  169   34    0    0    0   0   0   0   0  \n",
       "9     0    3  132  254  129    0    0    0   0   0   0   0  \n",
       "10    0    0    2  185  245   80    0    0   0   0   0   0  \n",
       "11    0    0    0  104  254  140    0    0   0   0   0   0  \n",
       "12    0    0    0   76  254  140    0    0   0   0   0   0  \n",
       "13    0    0    0  122  254   96    0    0   0   0   0   0  \n",
       "14    0    0    4  201  218   12    0    0   0   0   0   0  \n",
       "15  196  160  199  235  119    0    0    0   0   0   0   0  \n",
       "16  226  254  254  178    0    0    0    0   0   0   0   0  \n",
       "17   15   56  168  237  127    0    0    0   0   0   0   0  \n",
       "18    0    0    4  197  238   88    0    0   0   0   0   0  \n",
       "19    0    0    0   69  250  245   60    0   0   0   0   0  \n",
       "20    0    0    0    0  117  254  238   14   0   0   0   0  \n",
       "21    0    0    0    0   14  124  254  188  13   0   0   0  \n",
       "22    0    0    0    0    0    8  188  254  37   0   0   0  \n",
       "23    0    0    0    0    0    0   86  254  37   0   0   0  \n",
       "24    0    0    0    0    0    8  182  232  24   0   0   0  \n",
       "25    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "26    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "27    0    0    0    0    0    0    0    0   0   0   0   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 28)\n",
    "pd.DataFrame(sample_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb1203",
   "metadata": {},
   "source": [
    "이러한 이미지를 가지고, 학습을 하는 것이 중요해보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ca705",
   "metadata": {},
   "source": [
    "Remark. 눈치가 매우빠르신 분들은 다음과 같은 생각을 할지도 모르겠습니다.  \n",
    "'이거 혹시, 숫자의 위치가 중요하지 않을까?'  \n",
    "실제로 비어있는 위치가 달라질수도 있는 변수를 고려해볼 수 있지 않을까 생각해 볼 수 있겠습니다.  \n",
    "이는 뒤에서 고려해보기로 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f4f65",
   "metadata": {},
   "source": [
    "다음은 학습할 데이터가 균형이 잡혀있는지부터 확인해보려고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a960e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "4    500\n",
       "8    500\n",
       "1    500\n",
       "5    500\n",
       "9    500\n",
       "2    500\n",
       "6    500\n",
       "3    500\n",
       "7    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cda3c",
   "metadata": {},
   "source": [
    "학습할 데이터 자체는 균형잡혀있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0d522",
   "metadata": {},
   "source": [
    "## 두번째 관문, 신경망의 활용을 위한 데이터셋 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece70c2",
   "metadata": {},
   "source": [
    "신경망 활용을 위해, dataset을 만들고자 합니다.\n",
    "물론 한장한장 넣어서 학습시키는 방법이 있지만 여기서는 batch 개념을 활용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb62889",
   "metadata": {},
   "source": [
    "### 잠깐, batch에 대해서 알아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb6c52",
   "metadata": {},
   "source": [
    "### 다시 문제로 돌아와서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f00a3",
   "metadata": {},
   "source": [
    "CNN도 존재하지만, 일단은 간단한 방법론을 사용해봅시다.  \n",
    "pytorch를 활용하여 회귀식을 만들어 줄 수 있습니다.  \n",
    "최적의 회귀 계수는 경사하강법을 통해 찾게 된다고 생각하면 편합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa23c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만일 pip install torchvision이 안 될 경우 !를 붙여서 학습해줍시다.\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d65b585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "133bce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 함수는 baseline을 그대로 사용하겠습니다.\n",
    "# 이것을 통해 image -> 1차원 tensor으로 변환합니다.\n",
    "# pytorch에서는 학습을 위해서는 주어지는 데이터들은 모두 텐서 형태를 띄어야 합니다.!\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path_list, labels = None): \n",
    "        self.file_path_list = file_path_list\n",
    "        self.labels = labels\n",
    "        self.PIL2tensor = transforms.PILToTensor()\n",
    "        \n",
    "    def __getitem__(self, idx):       \n",
    "        image = Image.open(self.file_path_list[idx]) # 해당 인덱스에 맞는 image 추출\n",
    "        tensor_image = self.PIL2tensor(image) # PIL로 읽은 이미지를 torch tensor형으로 변환\n",
    "        flattened_image = tensor_image.flatten().float() # 2차원 이미지를 1차원으로 변환\n",
    "        \n",
    "        if self.labels is not None: # 라벨이 존재 하는경우: 학습에 이용할경우\n",
    "            label = self.labels[idx] # 해당 인덱스에 맞는 라벨 추출\n",
    "            return flattened_image, label  # 1차원으로 변환한 이미지와 라벨을 return\n",
    "        \n",
    "        return flattened_image # test단계에선 label이 존재하지 않기때문에 image만을 return\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049c787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_list = file_dir + train_df['file_name']\n",
    "labels = train_df['label']\n",
    "\n",
    "mnist_dataset = MNIST(file_path_list, labels)\n",
    "\n",
    "# data가 5000개이므로 50개씩 batch를 줍니다.\n",
    "# 보통 2의 거듭제곱꼴로 batch_size를 지정한다고 하나, 균등분배를 위해 50을 골랐습니다.\n",
    "# shuffle을 통해 label 값이 달라지도록 해줍시다. 하나의 batch(iteration)를 학습시킬 때 다양한 라벨을 보여줍시다.\n",
    "mnist_loader = DataLoader(mnist_dataset, batch_size = 50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b6473",
   "metadata": {},
   "source": [
    "### 세 번째 관문, 어떻게 학습을 시킬 것인가?, 결과를 어떻게 얻을 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ecfb8c",
   "metadata": {},
   "source": [
    "미니배치학습을 통해 하나씩 묶어서 학습을 시키도록 설정하였다.\n",
    "즉50개씩 100개의 배치를 한 번씩 학습하면 1epoch가 돌고, 몇epoch를 학습시킬 것인지를 결정해봅시다.\n",
    "일단, 모르니까 100번이나 학습해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea3832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_dim, class_num):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.pix2digit = nn.Linear(input_dim, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.pix2digit(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3383b",
   "metadata": {},
   "source": [
    "사실 , 엄밀하게 모든 과정을 이해하기 위해서는 오차항을 갱신시키는 경사하강법이나, 역전파 등에 대해 이해해야 합니다...\n",
    "(저도 정확하게 이해하고 있다고 자신하긴 어렵습니다..ㅠㅠ) 여기서는 어떻게 하는지만 감을 잡고 넘어갑시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed7730cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 113.51662\n",
      "epoch : 10, cost : 204.09618\n",
      "epoch : 20, cost : 224.79750\n",
      "epoch : 30, cost : 168.81978\n",
      "epoch : 40, cost : 99.93819\n",
      "epoch : 50, cost : 90.02641\n",
      "epoch : 60, cost : 48.65330\n",
      "epoch : 70, cost : 35.26298\n",
      "epoch : 80, cost : 15.78018\n",
      "epoch : 90, cost : 8.79246\n",
      "epoch : 100, cost : 4.59390\n"
     ]
    }
   ],
   "source": [
    "model = FullyConnected(784, 10)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(101):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for batch, labels in mnist_loader:\n",
    "        output = model(batch)\n",
    "        loss = ce_loss(output, labels)\n",
    "        loss.backward()  # 역전파입니다. \n",
    "        optim.step()\n",
    "        \n",
    "        avg_cost += loss / 100\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch : %d, cost : %.5f' %(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15155ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_dir = 'C:/Users/USER/Desktop/data_Practices/dacon_MNIST/test/'\n",
    "test_mnist_dataset = MNIST(test_file_dir + test_df['file_name'])\n",
    "test_mnist_loader = DataLoader(test_mnist_dataset, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa4f5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = None\n",
    "for test_batch in test_mnist_loader:\n",
    "    output = model(test_batch)\n",
    "    \n",
    "    digit_pred = output.detach().cpu().numpy().argmax(-1)\n",
    "    if preds is None:\n",
    "        preds = digit_pred\n",
    "    else:\n",
    "        preds = np.concatenate([preds, digit_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "034e2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae91969",
   "metadata": {},
   "source": [
    "단층의 경우 0.537% 의 정확도를 보이고 있다.\n",
    "이제 조금 더 신경을 써보려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78619c4",
   "metadata": {},
   "source": [
    "## 네 번째 관문, 비선형 활성화 함수의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec28c4c",
   "metadata": {},
   "source": [
    "앞에서까지는 선형함수만 활용하였다면, 비선형 함수를 활용하여, 층을 쌓아보려고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40e8d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonlinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, class_num):\n",
    "        super(NonlinearModel, self).__init__()\n",
    "        self.pix2hidden = nn.Linear(input_dim, 100)\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        self.hidden2hidden = nn.Linear(100, 50)\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        self.hidden2digit = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.pix2hidden(x)\n",
    "        output = self.ReLU1(output)\n",
    "        output = self.hidden2hidden(output)\n",
    "        output = self.ReLU2(output)\n",
    "        output = self.hidden2digit(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7daaef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 7.03029\n",
      "epoch : 10, cost : 0.39678\n",
      "epoch : 20, cost : 0.21973\n",
      "epoch : 30, cost : 0.12761\n",
      "epoch : 40, cost : 0.10147\n",
      "epoch : 50, cost : 0.06140\n",
      "epoch : 60, cost : 0.04631\n",
      "epoch : 70, cost : 0.04580\n",
      "epoch : 80, cost : 0.03484\n",
      "epoch : 90, cost : 0.01831\n",
      "epoch : 100, cost : 0.00844\n"
     ]
    }
   ],
   "source": [
    "model =  NonlinearModel(784, 10)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(101):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for batch, labels in mnist_loader:\n",
    "        output = model(batch)\n",
    "        loss = ce_loss(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        avg_cost += loss / 100\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch : %d, cost : %.5f' %(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf0a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = None\n",
    "for test_batch in test_mnist_loader:\n",
    "    output = model(test_batch)\n",
    "    \n",
    "    digit_pred = output.detach().cpu().numpy().argmax(-1)\n",
    "    if preds is None:\n",
    "        preds = digit_pred\n",
    "    else:\n",
    "        preds = np.concatenate([preds, digit_pred])\n",
    "        \n",
    "submission['label'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b714d",
   "metadata": {},
   "source": [
    "0.627 정도로 조금 더 좋은 결과를 얻었다.(Adagrad, lr = 1e-3 기준)\n",
    "Adam으로 변경한 결과를 확인하면 다음과 같습니다. 학습은 100번 진행."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1ac14",
   "metadata": {},
   "source": [
    "문제  /  Adam 1r = 1e-3에서 학습에 실패하였다.\n",
    "모두 1로 예측이 되어버렸다..?? 제대로 error가 줄어들지 않아서 lr를 낮춰 조절했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379a2dc",
   "metadata": {},
   "source": [
    "## 다섯 번째 관문, CNN의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c9d0d",
   "metadata": {},
   "source": [
    "이제 대표적인 신경망 중 하나인 CNN을 활용해보겠습니다.\n",
    "CNN까지 모두 설명하기엔 지면이 부족합니다.. 다만 CNN을 통해 하려는 것은 위의 방법론과는 다릅니다.\n",
    "일차원 형태로 텐서를 나타내었을 경우 위치 정보들을 제대로 반영하기가 어렵습니다. CNN을 통해서는 2차원 텐서 그대로를 이용합니다.\n",
    "즉, 2차원 텐서를 그대로 학습하여 위치별로, (픽셀 별로) 중요한 부분을 추출하여 학습할 수가 있습니다.\n",
    "\n",
    "이를 위해 2차원 텐서의 부분부분을 칸별로 이동하여 정보를 얻어오고, 이를 압축하는 과정을 거칩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4c8ec",
   "metadata": {},
   "source": [
    "### Dataloader 다시 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889cec7",
   "metadata": {},
   "source": [
    "그런데, 아뿔싸! 우리는 앞에서 만든 Dataloader는 1차원으로 만들어버린 것입니다.\n",
    "다시 한번, Dataloader를 만들어봅시다. 여기서는 2차원 형태로 전달해야 한다는 것을 잊지 맙시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c54d1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 함수는 baseline을 그대로 사용하겠습니다.\n",
    "# 다만, flatten이 없어집니다.! 이 차이 뿐입니다.\n",
    "# pytorch에서는 학습을 위해서는 주어지는 데이터들은 모두 텐서 형태를 띄어야 합니다.!\n",
    "\n",
    "class MNIST_2D(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path_list, labels = None): \n",
    "        self.file_path_list = file_path_list\n",
    "        self.labels = labels\n",
    "        self.PIL2tensor = transforms.PILToTensor()\n",
    "        \n",
    "    def __getitem__(self, idx):       \n",
    "        image = Image.open(self.file_path_list[idx]) # 해당 인덱스에 맞는 image 추출\n",
    "        tensor_image = self.PIL2tensor(image) # PIL로 읽은 이미지를 torch tensor형으로 변환\n",
    "        \n",
    "        if self.labels is not None: # 라벨이 존재 하는경우: 학습에 이용할경우\n",
    "            label = self.labels[idx] # 해당 인덱스에 맞는 라벨 추출\n",
    "            return tensor_image, label  # 1차원으로 변환한 이미지와 라벨을 return\n",
    "        \n",
    "        return tensor_image # test단계에선 label이 존재하지 않기때문에 image만을 return\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "553b8418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "1       C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "2       C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "3       C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "4       C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "                              ...                        \n",
       "4995    C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "4996    C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "4997    C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "4998    C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "4999    C:/Users/USER/Desktop/data_Practices/dacon_MNI...\n",
       "Name: file_name, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e83f0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label']\n",
    "mnist_dataset = MNIST_2D(file_path_list, labels)\n",
    "\n",
    "# data가 5000개이므로 50개씩 batch를 줍니다.\n",
    "# 보통 2의 거듭제곱꼴로 batch_size를 지정한다고 하나, 균등분배를 위해 50을 골랐습니다.\n",
    "# shuffle을 통해 label 값이 달라지도록 해줍시다. 하나의 batch(iteration)를 학습시킬 때 다양한 라벨을 보여줍시다.\n",
    "mnist_loader = DataLoader(mnist_dataset, batch_size = 50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be2bb0",
   "metadata": {},
   "source": [
    "### CNN 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a62d9",
   "metadata": {},
   "source": [
    "이제 CNN을 생성하고자 합니다. pytorch의 CNN은 Conv2d를 통해 불러올 수 있습니다.\n",
    "이것의 parameter부터 정리하겠습니다. 학습시에는 5개의 parameter를 입력하게 됩니다.\n",
    "- input\n",
    "- output\n",
    "- kernel_size\n",
    "- stride\n",
    "- padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236d901",
   "metadata": {},
   "source": [
    "여기서는 다음과 같은 순서로 하려고 한다.\n",
    "- self.conv1 (1채널 -> 16채널, kernel 5, stride = 1)  1 * 28 * 28 -> 16 * (24 * 24)\n",
    "- max_pooling (2칸씩 고려, stride = 2 ) 16 * (24 * 24) -> 16 * (12 * 12)\n",
    "- self.conv2 (16채널 -> 32채널, kernel 3, stride = 1)  -> 16 * (24 * 24) -> 32 * (10 * 10)\n",
    "- max_pooling (2칸씩 고려, stride = 2 ) -> 32 * (5 * 5)\n",
    "- 이를 1차원으로 핀다.\n",
    "- self.linear1 32 * 5 * 5 -> 200\n",
    "- self.linear2 200 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef5156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding은 고려하지 않음\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5, stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size = 3, stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.lin1 = nn.Linear(32*5*5, 200, bias = True)\n",
    "        self.lin2 = nn.Linear(200, 10, bias = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.lin1(output)\n",
    "        output = self.lin2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e173d2fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 6.63505\n",
      "epoch : 10, cost : 0.28817\n",
      "epoch : 20, cost : 0.11920\n",
      "epoch : 30, cost : 0.05697\n",
      "epoch : 40, cost : 0.02542\n",
      "epoch : 50, cost : 0.01101\n",
      "epoch : 60, cost : 0.00570\n",
      "epoch : 70, cost : 0.00321\n",
      "epoch : 80, cost : 0.00189\n",
      "epoch : 90, cost : 0.00115\n"
     ]
    }
   ],
   "source": [
    "model =  CNN_Net()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for batch, labels in mnist_loader:\n",
    "        optim.zero_grad()\n",
    "        batch = batch.float() # double -> float으로 변경하는 코드 추가.\n",
    "        output = model(batch)\n",
    "        loss = ce_loss(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        avg_cost += loss / 100\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch : %d, cost : %.5f' %(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d922706",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mnist_dataset = MNIST_2D(test_file_dir + test_df['file_name'])\n",
    "test_mnist_loader = DataLoader(test_mnist_dataset, batch_size = 50)\n",
    "preds = None\n",
    "for test_batch in test_mnist_loader:\n",
    "    test_batch = test_batch.float()\n",
    "    output = model(test_batch)\n",
    "    \n",
    "    digit_pred = output.detach().cpu().numpy().argmax(-1)\n",
    "    if preds is None:\n",
    "        preds = digit_pred\n",
    "    else:\n",
    "        preds = np.concatenate([preds, digit_pred])\n",
    "        \n",
    "submission['label'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0701222",
   "metadata": {},
   "source": [
    "현재로서는 Test 0.647로 가장 괜찮은 성과를 얻었다. 하지만 모델을 조금 더 조정하고 학습해보려고 한다.\n",
    "padding을 항상 추가 후, max_pool에서도 stride = 1로 조금 더 많은 정보를 추출하는 쪽으로 모델을 생성했다.\n",
    "이 때, layer3까지 한 번의 CNN을 더 통과시켜보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a0913fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding은 고려, max_pooling stride = 1로 재조절.\n",
    "class CNN_Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net2, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 1))\n",
    "        \n",
    "        # 16 * 25 * 25 size를 얻게 된다.\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size = 5, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 1))\n",
    "        \n",
    "        # 32 * 22 * 22 size를 얻게 된다.\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size = 5, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 1))\n",
    "        \n",
    "        # 32 * 19 * 19 을 얻었다.\n",
    "        \n",
    "        self.lin1 = nn.Linear(32*19*19, 500, bias = True)\n",
    "        self.lin_ReLU = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(500, 10, bias = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.lin1(output)\n",
    "        output = self.lin_ReLU(output)\n",
    "        output = self.lin2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76752df0",
   "metadata": {},
   "source": [
    "층이 많이 깊어졌으므로, 오버피팅을 막아야 할 거 가은 생각에 층은 50층으로 조절해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5efe0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 0.61037\n",
      "epoch : 10, cost : 0.00224\n",
      "epoch : 20, cost : 0.00057\n",
      "epoch : 30, cost : 0.00022\n",
      "epoch : 40, cost : 0.00009\n"
     ]
    }
   ],
   "source": [
    "model =  CNN_Net2()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for batch, labels in mnist_loader:\n",
    "        optim.zero_grad()\n",
    "        batch = batch.float() # double -> float으로 변경하는 코드 추가.\n",
    "        output = model(batch)\n",
    "        loss = ce_loss(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        avg_cost += loss / 100\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch : %d, cost : %.5f' %(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8792ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mnist_dataset = MNIST_2D(test_file_dir + test_df['file_name'])\n",
    "test_mnist_loader = DataLoader(test_mnist_dataset, batch_size = 50)\n",
    "preds = None\n",
    "for test_batch in test_mnist_loader:\n",
    "    test_batch = test_batch.float()\n",
    "    output = model(test_batch)\n",
    "    \n",
    "    digit_pred = output.detach().cpu().numpy().argmax(-1)\n",
    "    if preds is None:\n",
    "        preds = digit_pred\n",
    "    else:\n",
    "        preds = np.concatenate([preds, digit_pred])\n",
    "        \n",
    "submission['label'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90480a",
   "metadata": {},
   "source": [
    "71.1%로 굉장히 정확도를 많이 올렸지만 아직 조금 더 정확도를 올릴 좋은 방법을 생각해보려고합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370435f",
   "metadata": {},
   "source": [
    "## 더 나아가기 위한 방향성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec715122",
   "metadata": {},
   "source": [
    "여기서는 저의 부족(?)으로 더 진행이 어렵지만, 다음과 같은 방법론을 고려해볼 수 있습니다.\n",
    "- CNN과 관련된 유명한 이름있는 모델들이 많다고 알고있습니다. (AlexNet, ResNet 등).\n",
    "- 이번 대회에서는 Pre-trained된 모델은 쓸 수 없기에, 조심스럽지만 이들을 활용할만한 방법이 있을 것입니다.\n",
    "- GAN을 적용할 방법에 대해 고민해 볼 수 있을 것입니다.\n",
    "- 데이터를 어떻게 증강시킬지에 대해 고민합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171a67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
